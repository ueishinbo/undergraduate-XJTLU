# Week1

## K近邻算法

k近邻算法是一种**基本分类和回归方法**。本篇文章只讨论分类问题的k近邻法。



K近邻算法，即是给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例**最邻近**的K个实例，**这K个实例的多数属于某个类**，就把该输入实例分类到这个类中。（**这就类似于现实生活中少数服从多数的思想**）根据这个说法，咱们来看下引自维基百科上的一幅图：

<img src="https://i.loli.net/2021/11/10/s4URlMmG6ipQLgy.png" alt="WX20211110-025327@2x.png" style="zoom:50%;" />

如上图所示，有**两类**不同的样本数据，分别用蓝色的小正方形和红色的小三角形表示，而图正中间的那个绿色的圆所标示的数据则是**待分类的数据**。这也就是我们的目的，来了一个新的数据点，我要得到它的类别是什么？好的，下面我们根据k近邻的思想来给绿色圆点进行分类。

- 如果K=3，绿色圆点的最邻近的3个点是2个红色小三角形和1个蓝色小正方形，**少数从属于多数，**基于统计的方法，判定绿色的这个待分类点属于红色的三角形一类。
- 如果K=5，绿色圆点的最邻近的5个邻居是2个红色三角形和3个蓝色的正方形，**还是少数从属于多数，**基于统计的方法，判定绿色的这个待分类点属于蓝色的正方形一类。

从上面例子我们可以看出，k近邻的算法思想非常的简单，也非常的容易理解，那么我们是不是就到此结束了，**该算法的原理我们也已经懂了，也知道怎么给新来的点如何进行归类，只要找到离它最近的k个实例，哪个类别最多即可。**



**k怎么确定的，k为多少效果最好呢？所谓的最近邻又是如何来判断给定呢？**

https://zhuanlan.zhihu.com/p/25994179

# Week 2



# 深度学习--卷积神经网络

## 边缘检测

边缘检测就是使用filter检测原来图像中的边界在哪来。

下面的3*3矩阵是一个垂直边缘filter，它可以监测出图像的边缘部分

<img src="https://i.loli.net/2021/11/21/QCHRKEyNq2csitO.png" alt="WX20211121-161140@2x.png" style="zoom:50%;" />

### 垂直监测

在下图中，左边是原来的图像，中间是filter右边是卷积计算后的结果，（数字越大代表该区域像素越白，反之代表越黑）。每个矩阵的下面代表的是每个矩阵的可视化图。

![WX20211121-161539@2x.png](https://i.loli.net/2021/11/21/a9Sh2G7w1DUFrJp.png)

最左边的绿色区域对标的是右边图的绿色区域，发现没有数值变化，所以没有垂直边缘。左图的红色区域对标的是有图的红色的区域，发现有数值变化，刚好也就是说明该区域有垂直边界。

### 其他监测

#### 水平监测

![WX20211121-165509@2x.png](https://i.loli.net/2021/11/21/cjOumyrz6wR3UvW.png)

右边中有10是因为去了中间值的缘故，10太大了是因为这个像素太少，如果是1000*1000这个中间值就不会这么大

还有多种多样的监测方式比如35度角73度角，可以查。不要去造轮子。

但是如果你想监测出一个复杂图像的边缘，你不一定需要那些研究者们所做出来filter的9个数字，你可以把这九个数字当成参数之后，你可以学习反向传播算法，其目标就是为了理解这9个参数，当你得到一个n*n的图像时，将带参数的fiter进行卷积计算，然后得到一个出色的边缘检测filter。

## padding

为了构建深度神经网络，你需要学会使用一个基础的卷积操作就是padding

如果你现在有一个N*N的图像，然后一个f✖️f的filter，最终你会的到一个（N-f+1）✖️（N-f+1）的结果

但是这样有两个缺点：

1. 每次做卷积操作的时候，你的图像就会变小，可能你做几次之后你的图像会缩到1*1
2. 图片的边缘像素被使用次数太小，在中间区域使用次数太多。就比如最左上角的格子，他只被运算一次，而红色格子会被计算很多次，

<img src="https://i.loli.net/2021/11/21/NlFTQUIZSdR8rYi.png" alt="WX20211121-171059@2x.png" style="zoom:50%;" />

解决办法1：在卷积操作前给周围再填充一层像素，就比如上图，原来是6✖️6的图片，填充一层后就变成了8✖️8，且填充的像素都为0.也就是说padding = 1

此时如果你用一个个N*N的图像，然后一个f✖️f的filter，然后加上一个p的padding， 最终你会的到一个（N+2p-f+1）✖️（N+2p-f+1）的结果。（p是padding）



如何选择padding的大小，这里有两种选择方式：Vaild卷积和Same卷积

Vaild卷积意味着padding为0就是不加padding

Same卷积意味着你的输入大小和输出大小是一样的，也就是说你输入一个N\*N的图片，你的输出也是一个N\*N

## 卷积步长 strided

就是filter每次移动的距离。（包括水平和垂直移动的距离）。就比如filter是2，你每次往右就得移动两次，向下也是一样。

此时的输入是N\*N的图像，然后一个f✖️f的filter，然后加上一个p的padding，最后加一个s，最终的输出结果是：(N+2p-f)/s + 1 ✖️(N+2p-f)/s + 1 的图像（如果除运算不是整数，可以对两边的维度进行向下取整操作）。

如果由于步长的缘故导致最右边又几列会出去，则把着一次运算删除掉。

## 简单神经网络实例

假设现在有一个39✖️39✖️3的图像，所以**n<sub>H</sub><sup>[0]</sup> = n<sub>W</sub><sub>[0]</sub> = 39**,n<sub>c</sub><sup>[0]</sup> = 3

<img src="https://i.loli.net/2021/11/23/HOKbczqpUj6nRv3.png" alt="WX20211123-005252@2x.png" style="zoom:50%;" />

然后我们用一个3✖️3的filter来提取原图像的feature，也就是说f<sup>[0]</sup> = 3.其次我们设步长 = 1，没有paddings也就是说s<sup>[1]</sup> = 1, p<sup>[1]</sup> = 0.如果有10个filter。

根据公式：((n+2p-f)/s) + 1算出下一层的激活层也就是((39+0-3)/1)+1 = 37, 也就是说输出为 37 ✖️ 37 ✖️10，此时的输入为下一层的输入，也就是说下一层标记为**n<sub>H</sub><sup>[1]</sup> = n<sub>W</sub><sup>[1]</sup> = 37,   n<sub>c</sub><sup>[1]</sup> = 10**![WX20211123-010701@2x.png](https://i.loli.net/2021/11/23/de1yhRCIlJLGUqz.png)

假设你现在还有下一个卷积  



















